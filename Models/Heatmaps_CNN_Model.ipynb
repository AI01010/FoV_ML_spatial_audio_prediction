{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Fusion Model"
      ],
      "metadata": {
        "id": "yibjUqF6Q1LK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # take 3-5 heatmaps of a single frame\n",
        "    # tile each into 16*9 tiles and label each tile with single index going per column from left to right, per row from top to bottom\n",
        "    # convert into 3d matrix (each depth is a heatmap)\n",
        "    # size of input matrix (16*pixWidthPerTile)*(9*pixHeightPerTile)*(3|4|5)\n",
        "    # assume 4k consumer/customer market standard: 4k(3840x1920)\n",
        "    # also take the head direction center and the corresponding tile's index for data per frame as input\n",
        "    # we should be taking the 3d matrix of heatmaps and the tile index where the user is looking per frame as out data\n",
        "    # predict the tile that the user will look at based on the heatmaps (weighted by each heatmap then fused) to find the tile with highest saliency\n",
        "    # check the predicted tile index vs the actual inputted tile index for user view\n",
        "    # loss/error function will be the difference in tile index (using the standard loss func) to optimize by minimizing the loss\n",
        "    # do this per frame and get an accuracy as well as runtime calculation"
      ],
      "metadata": {
        "id": "92Xznc8GQyvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWa1egndri88",
        "outputId": "f11ccedd-3eed-4648-c240-feda0d18ae3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "============================================================\n",
            "360° Video Saliency-Based Tile Predictor\n",
            "============================================================\n",
            "\n",
            "Configuration:\n",
            "  Frame size: 960x480 (25% of 4K)\n",
            "  Grid: 16x9 = 144 tiles\n",
            "  Tile size: 60x53\n",
            "  Heatmaps per frame: 9\n",
            "  Video: 3s @ 60fps = 180 total frames\n",
            "  Sampling: Every 5th frame = 36 sampled frames\n",
            "\n",
            "\n",
            "============================================================\n",
            "Generating Synthetic Video Data\n",
            "============================================================\n",
            "\n",
            "Videos: 1\n",
            "Duration: 3s @ 60 FPS = 180 total frames\n",
            "Sampling: Every 5th frame = 36 sampled frames\n",
            "Heatmap resolution: 960x480 (25% of 4K)\n",
            "Total sampled frames: 36\n",
            "\n",
            "Generating video 1/1...\n",
            "\n",
            "Data generation complete!\n",
            "  Heatmaps 4D shape: (1, 36, 9, 480, 960)\n",
            "  Tile indices shape: (1, 36)\n",
            "  Memory usage: 597.2 MB\n",
            "\n",
            "============================================================\n",
            "Data Structure:\n",
            "============================================================\n",
            "4D Heatmaps Matrix: (1, 36, 9, 480, 960)\n",
            "  [videos, sampled_frames, heatmaps, height, width]\n",
            "  [1, 36, 9, 480, 960]\n",
            "  - 1 video\n",
            "  - 36 sampled frames (every 5th frame from 180 total @ 60 FPS)\n",
            "  - 9 heatmaps per frame (7 audio + 2 video)\n",
            "  - 480x960 resolution (25% of 4K)\n",
            "\n",
            "1D Tile Index Array: (1, 36)\n",
            "  [videos, sampled_frames]\n",
            "  [1, 36]\n",
            "  - 1 user's viewing data\n",
            "  - 36 tile indices (sampled every 5th frame, range 0-143)\n",
            "  - Each index represents which tile user is looking at\n",
            "============================================================\n",
            "\n",
            "Flattened for Training:\n",
            "  Heatmaps: (36, 9, 480, 960)\n",
            "  Tile indices: (36,)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 25 | Val: 5 | Test: 6\n",
            "\n",
            "Model parameters: 660,864\n",
            "\n",
            "Training started...\n",
            "\n",
            "Epoch 1/15: Train 12.0% | Val 0.0% | Dist 1.63 | 7.5s\n",
            "Epoch 2/15: Train 52.0% | Val 0.0% | Dist 1.25 | 7.2s\n",
            "Epoch 3/15: Train 56.0% | Val 0.0% | Dist 1.25 | 6.5s\n",
            "Epoch 4/15: Train 68.0% | Val 0.0% | Dist 1.25 | 7.3s\n",
            "Epoch 5/15: Train 72.0% | Val 0.0% | Dist 1.25 | 6.4s\n",
            "Epoch 6/15: Train 80.0% | Val 0.0% | Dist 1.25 | 7.3s\n",
            "Epoch 7/15: Train 92.0% | Val 40.0% | Dist 0.68 | 6.5s\n",
            "Epoch 8/15: Train 84.0% | Val 0.0% | Dist 1.25 | 7.3s\n",
            "Epoch 9/15: Train 88.0% | Val 0.0% | Dist 1.25 | 6.7s\n",
            "Epoch 10/15: Train 84.0% | Val 40.0% | Dist 0.68 | 7.0s\n",
            "Epoch 11/15: Train 88.0% | Val 60.0% | Dist 0.40 | 7.0s\n",
            "Epoch 12/15: Train 88.0% | Val 60.0% | Dist 0.40 | 7.5s\n",
            "Epoch 13/15: Train 88.0% | Val 60.0% | Dist 0.40 | 7.2s\n",
            "Epoch 14/15: Train 92.0% | Val 60.0% | Dist 0.40 | 6.3s\n",
            "Epoch 15/15: Train 88.0% | Val 60.0% | Dist 0.40 | 7.2s\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "============================================================\n",
            "Training Complete!\n",
            "============================================================\n",
            "\n",
            "Best Val Accuracy: 60.00%\n",
            "Test Accuracy: 83.33%\n",
            "Test Avg Tile Distance: 0.24 tiles\n",
            "Total Training Time: 104.9s (1.7 min)\n",
            "\n",
            "  Epoch    Train Loss  Train Acc      Val Loss  Val Acc      Tile Dist  Time\n",
            "-------  ------------  -----------  ----------  ---------  -----------  ------\n",
            "      1        4.4884  12.0%            4.9501  0.0%              1.63  7.5s\n",
            "      2        2.339   52.0%            4.7401  0.0%              1.25  7.2s\n",
            "      3        1.3447  56.0%            4.3991  0.0%              1.25  6.5s\n",
            "      4        1.2945  68.0%            3.9693  0.0%              1.25  7.3s\n",
            "      5        0.9937  72.0%            3.6458  0.0%              1.25  6.4s\n",
            "      6        1.108   80.0%            3.383   0.0%              1.25  7.3s\n",
            "      7        0.5322  92.0%            3.1514  40.0%             0.68  6.5s\n",
            "      8        0.4406  84.0%            3.062   0.0%              1.25  7.3s\n",
            "      9        0.4398  88.0%            3.031   0.0%              1.25  6.7s\n",
            "     10        0.4505  84.0%            2.9595  40.0%             0.68  7.0s\n",
            "     11        0.322   88.0%            2.7705  60.0%             0.4   7.0s\n",
            "     12        0.3334  88.0%            2.6836  60.0%             0.4   7.5s\n",
            "     13        0.31    88.0%            2.6682  60.0%             0.4   7.2s\n",
            "     14        0.2671  92.0%            2.669   60.0%             0.4   6.3s\n",
            "     15        0.2312  88.0%            2.699   60.0%             0.4   7.2s\n",
            "\n",
            "============================================================\n",
            "Inference Speed Test\n",
            "============================================================\n",
            "\n",
            "Average inference: 33.68ms\n",
            "Throughput: 29.7 FPS\n",
            "Can process: 0.5x realtime\n",
            "Sample prediction: Tile 58 at (10, 3)\n",
            "\n",
            "============================================================\n",
            "Model saved as 'best_model.pth'\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "User Viewing Data - Video 0 (3 seconds, every 5th frame)\n",
            "============================================================\n",
            "Sample# | Frame# | Time(s) | Tile Index | Tile Grid (x,y)\n",
            "------------------------------------------------------------\n",
            "      0 |      0 |   0.00  |         59 | (11,  3)\n",
            "      3 |     15 |   0.25  |         58 | (10,  3)\n",
            "      6 |     30 |   0.50  |         58 | (10,  3)\n",
            "      9 |     45 |   0.75  |         58 | (10,  3)\n",
            "     12 |     60 |   1.00  |         74 | (10,  4)\n",
            "     15 |     75 |   1.25  |         58 | (10,  3)\n",
            "     18 |     90 |   1.50  |         73 | ( 9,  4)\n",
            "     21 |    105 |   1.75  |         73 | ( 9,  4)\n",
            "     24 |    120 |   2.00  |         73 | ( 9,  4)\n",
            "     27 |    135 |   2.25  |         73 | ( 9,  4)\n",
            "     30 |    150 |   2.50  |         72 | ( 8,  4)\n",
            "     33 |    165 |   2.75  |         88 | ( 8,  5)\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision tqdm tabulate --quiet\n",
        "\n",
        "import time, os, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\\n\")\n",
        "\n",
        "# Configuration - 25% of 4K resolution\n",
        "FRAME_WIDTH = 960    # 25% of 3840\n",
        "FRAME_HEIGHT = 480   # 25% of 1920\n",
        "TILES_X = 16\n",
        "TILES_Y = 9\n",
        "NUM_TILES = TILES_X * TILES_Y  # 144 tiles\n",
        "TILE_WIDTH = FRAME_WIDTH // TILES_X   # 60 pixels\n",
        "TILE_HEIGHT = FRAME_HEIGHT // TILES_Y  # ~53 pixels\n",
        "NUM_HEATMAPS = 9  # 7 audio + 2 video\n",
        "\n",
        "# Video configuration\n",
        "FPS = 60  # Frames per second (full framerate)\n",
        "VIDEO_DURATION = 3  # seconds\n",
        "FRAME_SAMPLE_RATE = 5  # Take every 5th frame\n",
        "TOTAL_FRAMES = FPS * VIDEO_DURATION  # 180 frames total for 3 seconds\n",
        "FRAMES_PER_VIDEO = TOTAL_FRAMES // FRAME_SAMPLE_RATE  # 36 sampled frames\n",
        "\n",
        "class SaliencyTileDataset(Dataset):\n",
        "    \"\"\"Memory-efficient dataset for saliency heatmaps\"\"\"\n",
        "\n",
        "    def __init__(self, heatmaps, tile_indices):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            heatmaps: numpy array of shape (N_frames, NUM_HEATMAPS, H, W)\n",
        "            tile_indices: numpy array of shape (N_frames,) with tile indices [0-143]\n",
        "        \"\"\"\n",
        "        # Convert to float32 for memory efficiency\n",
        "        self.heatmaps = heatmaps.astype(np.float32)\n",
        "        self.tile_indices = tile_indices.astype(np.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tile_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        heatmap = torch.from_numpy(self.heatmaps[idx])\n",
        "        tile_idx = torch.tensor(self.tile_indices[idx], dtype=torch.long)\n",
        "        return heatmap, tile_idx\n",
        "\n",
        "\n",
        "class HeatmapFusionCNN(nn.Module):\n",
        "    \"\"\"Lightweight CNN for fusing saliency heatmaps\"\"\"\n",
        "\n",
        "    def __init__(self, num_heatmaps=9, num_tiles=144, dropout=0.3):\n",
        "        super(HeatmapFusionCNN, self).__init__()\n",
        "\n",
        "        # Heatmap fusion with 1x1 conv\n",
        "        self.fusion = nn.Conv2d(num_heatmaps, 8, kernel_size=1)\n",
        "\n",
        "        # Lightweight feature extraction\n",
        "        self.conv1 = nn.Conv2d(8, 32, kernel_size=5, stride=4, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Adaptive pooling\n",
        "        self.pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "\n",
        "        # Classifier\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(256, num_tiles)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Fuse heatmaps\n",
        "        x = self.fusion(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Feature extraction\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Pool and classify\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def tile_coords_to_index(x, y, tiles_x=TILES_X):\n",
        "    \"\"\"Convert tile coordinates to linear index\"\"\"\n",
        "    return y * tiles_x + x\n",
        "\n",
        "\n",
        "def tile_index_to_coords(idx, tiles_x=TILES_X):\n",
        "    \"\"\"Convert linear index to tile coordinates\"\"\"\n",
        "    y = idx // tiles_x\n",
        "    x = idx % tiles_x\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def tile_distance(pred_idx, true_idx, tiles_x=TILES_X):\n",
        "    \"\"\"Calculate tile distance\"\"\"\n",
        "    px, py = tile_index_to_coords(pred_idx, tiles_x)\n",
        "    tx, ty = tile_index_to_coords(true_idx, tiles_x)\n",
        "    return np.sqrt((px - tx)**2 + (py - ty)**2)\n",
        "\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for heatmaps, tile_indices in dataloader:\n",
        "        heatmaps = heatmaps.to(device)\n",
        "        tile_indices = tile_indices.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(heatmaps)\n",
        "        loss = criterion(outputs, tile_indices)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += tile_indices.size(0)\n",
        "        correct += predicted.eq(tile_indices).sum().item()\n",
        "\n",
        "    return total_loss / len(dataloader), 100. * correct / total\n",
        "\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    tile_distances = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for heatmaps, tile_indices in dataloader:\n",
        "            heatmaps = heatmaps.to(device)\n",
        "            tile_indices = tile_indices.to(device)\n",
        "\n",
        "            outputs = model(heatmaps)\n",
        "            loss = criterion(outputs, tile_indices)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += tile_indices.size(0)\n",
        "            correct += predicted.eq(tile_indices).sum().item()\n",
        "\n",
        "            for pred, true in zip(predicted.cpu().numpy(), tile_indices.cpu().numpy()):\n",
        "                tile_distances.append(tile_distance(pred, true))\n",
        "\n",
        "    avg_distance = np.mean(tile_distances)\n",
        "    return total_loss / len(dataloader), 100. * correct / total, avg_distance\n",
        "\n",
        "\n",
        "def generate_synthetic_video_data(num_videos=1):\n",
        "    \"\"\"\n",
        "    Generate synthetic video data at 60 FPS, sampling every 5th frame\n",
        "\n",
        "    Returns:\n",
        "        heatmaps_4d: shape (num_videos, FRAMES_PER_VIDEO, NUM_HEATMAPS, H, W)\n",
        "        tile_indices_1d: shape (num_videos, FRAMES_PER_VIDEO)\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Generating Synthetic Video Data\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    print(f\"Videos: {num_videos}\")\n",
        "    print(f\"Duration: {VIDEO_DURATION}s @ {FPS} FPS = {TOTAL_FRAMES} total frames\")\n",
        "    print(f\"Sampling: Every {FRAME_SAMPLE_RATE}th frame = {FRAMES_PER_VIDEO} sampled frames\")\n",
        "    print(f\"Heatmap resolution: {FRAME_WIDTH}x{FRAME_HEIGHT} (25% of 4K)\")\n",
        "    print(f\"Total sampled frames: {num_videos * FRAMES_PER_VIDEO}\\n\")\n",
        "\n",
        "    # Initialize 4D matrix for heatmaps: (videos, sampled_frames, heatmaps, height, width)\n",
        "    heatmaps_4d = np.zeros((num_videos, FRAMES_PER_VIDEO, NUM_HEATMAPS,\n",
        "                            FRAME_HEIGHT, FRAME_WIDTH), dtype=np.float32)\n",
        "\n",
        "    # Initialize 1D matrix for tile indices: (videos, sampled_frames)\n",
        "    tile_indices_1d = np.zeros((num_videos, FRAMES_PER_VIDEO), dtype=np.int64)\n",
        "\n",
        "    for video_idx in range(num_videos):\n",
        "        print(f\"Generating video {video_idx + 1}/{num_videos}...\")\n",
        "\n",
        "        # Create a smooth trajectory for the salient region across ALL frames\n",
        "        start_x = np.random.randint(TILE_WIDTH * 2, FRAME_WIDTH - TILE_WIDTH * 2)\n",
        "        start_y = np.random.randint(TILE_HEIGHT * 2, FRAME_HEIGHT - TILE_HEIGHT * 2)\n",
        "\n",
        "        end_x = np.random.randint(TILE_WIDTH * 2, FRAME_WIDTH - TILE_WIDTH * 2)\n",
        "        end_y = np.random.randint(TILE_HEIGHT * 2, FRAME_HEIGHT - TILE_HEIGHT * 2)\n",
        "\n",
        "        # Create smooth trajectory for ALL 180 frames (60 FPS * 3 sec)\n",
        "        trajectory_x = np.linspace(start_x, end_x, TOTAL_FRAMES)\n",
        "        trajectory_y = np.linspace(start_y, end_y, TOTAL_FRAMES)\n",
        "\n",
        "        # Add jitter\n",
        "        jitter_x = np.random.randn(TOTAL_FRAMES) * (TILE_WIDTH / 4)\n",
        "        jitter_y = np.random.randn(TOTAL_FRAMES) * (TILE_HEIGHT / 4)\n",
        "\n",
        "        trajectory_x = np.clip(trajectory_x + jitter_x, 0, FRAME_WIDTH - 1)\n",
        "        trajectory_y = np.clip(trajectory_y + jitter_y, 0, FRAME_HEIGHT - 1)\n",
        "\n",
        "        # Sample every 5th frame\n",
        "        sampled_frame_idx = 0\n",
        "        for full_frame_idx in range(0, TOTAL_FRAMES, FRAME_SAMPLE_RATE):\n",
        "            # Current center of attention at this frame\n",
        "            cx = int(trajectory_x[full_frame_idx])\n",
        "            cy = int(trajectory_y[full_frame_idx])\n",
        "\n",
        "            # Generate heatmaps for this sampled frame\n",
        "            fused_saliency = np.zeros((FRAME_HEIGHT, FRAME_WIDTH), dtype=np.float32)\n",
        "\n",
        "            for heatmap_idx in range(NUM_HEATMAPS):\n",
        "                # Random sigma for variety in saliency spread\n",
        "                sigma = FRAME_WIDTH / (6 + np.random.rand() * 4)  # Varies between /6 and /10\n",
        "\n",
        "                # Add small random offset for each heatmap\n",
        "                offset_x = np.random.randint(-TILE_WIDTH//2, TILE_WIDTH//2)\n",
        "                offset_y = np.random.randint(-TILE_HEIGHT//2, TILE_HEIGHT//2)\n",
        "\n",
        "                center_x = np.clip(cx + offset_x, 0, FRAME_WIDTH - 1)\n",
        "                center_y = np.clip(cy + offset_y, 0, FRAME_HEIGHT - 1)\n",
        "\n",
        "                # Create Gaussian saliency map\n",
        "                y, x = np.ogrid[:FRAME_HEIGHT, :FRAME_WIDTH]\n",
        "                heatmap = np.exp(-((x - center_x)**2 + (y - center_y)**2) / (2 * sigma**2))\n",
        "\n",
        "                # Store heatmap\n",
        "                heatmaps_4d[video_idx, sampled_frame_idx, heatmap_idx] = heatmap\n",
        "\n",
        "                # Accumulate saliency (equal weight, let model learn optimal fusion)\n",
        "                fused_saliency += heatmap\n",
        "\n",
        "            # Find the tile with maximum saliency\n",
        "            max_y, max_x = np.unravel_index(fused_saliency.argmax(), fused_saliency.shape)\n",
        "            tile_x = min(max_x // TILE_WIDTH, TILES_X - 1)\n",
        "            tile_y = min(max_y // TILE_HEIGHT, TILES_Y - 1)\n",
        "            tile_idx = tile_coords_to_index(tile_x, tile_y)\n",
        "\n",
        "            # Store tile index for this sampled frame\n",
        "            tile_indices_1d[video_idx, sampled_frame_idx] = tile_idx\n",
        "\n",
        "            sampled_frame_idx += 1\n",
        "\n",
        "    print(f\"\\nData generation complete!\")\n",
        "    print(f\"  Heatmaps 4D shape: {heatmaps_4d.shape}\")\n",
        "    print(f\"  Tile indices shape: {tile_indices_1d.shape}\")\n",
        "    print(f\"  Memory usage: {heatmaps_4d.nbytes / 1e6:.1f} MB\\n\")\n",
        "\n",
        "    return heatmaps_4d, tile_indices_1d\n",
        "\n",
        "\n",
        "def flatten_video_data(heatmaps_4d, tile_indices_1d):\n",
        "    \"\"\"\n",
        "    Flatten video data from (videos, frames, ...) to (total_frames, ...)\n",
        "\n",
        "    Args:\n",
        "        heatmaps_4d: shape (num_videos, frames_per_video, num_heatmaps, H, W)\n",
        "        tile_indices_1d: shape (num_videos, frames_per_video)\n",
        "\n",
        "    Returns:\n",
        "        heatmaps: shape (total_frames, num_heatmaps, H, W)\n",
        "        tile_indices: shape (total_frames,)\n",
        "    \"\"\"\n",
        "    num_videos, frames_per_video = tile_indices_1d.shape\n",
        "    total_frames = num_videos * frames_per_video\n",
        "\n",
        "    # Reshape heatmaps: (videos, frames, heatmaps, H, W) -> (total_frames, heatmaps, H, W)\n",
        "    heatmaps = heatmaps_4d.reshape(total_frames, NUM_HEATMAPS, FRAME_HEIGHT, FRAME_WIDTH)\n",
        "\n",
        "    # Flatten tile indices: (videos, frames) -> (total_frames,)\n",
        "    tile_indices = tile_indices_1d.reshape(total_frames)\n",
        "\n",
        "    return heatmaps, tile_indices\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"360° Video Saliency-Based Tile Predictor\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    print(f\"Configuration:\")\n",
        "    print(f\"  Frame size: {FRAME_WIDTH}x{FRAME_HEIGHT} (25% of 4K)\")\n",
        "    print(f\"  Grid: {TILES_X}x{TILES_Y} = {NUM_TILES} tiles\")\n",
        "    print(f\"  Tile size: {TILE_WIDTH}x{TILE_HEIGHT}\")\n",
        "    print(f\"  Heatmaps per frame: {NUM_HEATMAPS}\")\n",
        "    print(f\"  Video: {VIDEO_DURATION}s @ {FPS}fps = {TOTAL_FRAMES} total frames\")\n",
        "    print(f\"  Sampling: Every {FRAME_SAMPLE_RATE}th frame = {FRAMES_PER_VIDEO} sampled frames\\n\")\n",
        "\n",
        "    # Generate synthetic video data - just 1 video for memory efficiency\n",
        "    num_videos = 1  # 1 video of 3 seconds\n",
        "    heatmaps_4d, tile_indices_1d = generate_synthetic_video_data(num_videos=num_videos)\n",
        "\n",
        "    print(f\"{'='*60}\")\n",
        "    print(\"Data Structure:\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"4D Heatmaps Matrix: {heatmaps_4d.shape}\")\n",
        "    print(f\"  [videos, sampled_frames, heatmaps, height, width]\")\n",
        "    print(f\"  [1, 36, 9, 480, 960]\")\n",
        "    print(f\"  - 1 video\")\n",
        "    print(f\"  - 36 sampled frames (every 5th frame from 180 total @ 60 FPS)\")\n",
        "    print(f\"  - 9 heatmaps per frame (7 audio + 2 video)\")\n",
        "    print(f\"  - 480x960 resolution (25% of 4K)\")\n",
        "    print(f\"\\n1D Tile Index Array: {tile_indices_1d.shape}\")\n",
        "    print(f\"  [videos, sampled_frames]\")\n",
        "    print(f\"  [1, 36]\")\n",
        "    print(f\"  - 1 user's viewing data\")\n",
        "    print(f\"  - 36 tile indices (sampled every 5th frame, range 0-143)\")\n",
        "    print(f\"  - Each index represents which tile user is looking at\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Flatten data for training\n",
        "    heatmaps_flat, tile_indices_flat = flatten_video_data(heatmaps_4d, tile_indices_1d)\n",
        "\n",
        "    print(f\"Flattened for Training:\")\n",
        "    print(f\"  Heatmaps: {heatmaps_flat.shape}\")\n",
        "    print(f\"  Tile indices: {tile_indices_flat.shape}\\n\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = SaliencyTileDataset(heatmaps_flat, tile_indices_flat)\n",
        "\n",
        "    # Split\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(\n",
        "        dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
        "\n",
        "    print(f\"Dataset splits:\")\n",
        "    print(f\"  Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\\n\")\n",
        "\n",
        "    # Initialize model\n",
        "    model = HeatmapFusionCNN(num_heatmaps=NUM_HEATMAPS, num_tiles=NUM_TILES).to(device)\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Model parameters: {total_params:,}\\n\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
        "\n",
        "    # Training\n",
        "    num_epochs = 15\n",
        "    best_val_acc = 0\n",
        "    results = []\n",
        "\n",
        "    print(\"Training started...\\n\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc, avg_tile_dist = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        epoch_time = time.time() - epoch_start\n",
        "\n",
        "        results.append([\n",
        "            epoch + 1,\n",
        "            f\"{train_loss:.4f}\",\n",
        "            f\"{train_acc:.1f}%\",\n",
        "            f\"{val_loss:.4f}\",\n",
        "            f\"{val_acc:.1f}%\",\n",
        "            f\"{avg_tile_dist:.2f}\",\n",
        "            f\"{epoch_time:.1f}s\"\n",
        "        ])\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
        "              f\"Train {train_acc:.1f}% | Val {val_acc:.1f}% | \"\n",
        "              f\"Dist {avg_tile_dist:.2f} | {epoch_time:.1f}s\")\n",
        "\n",
        "        # Clear cache periodically\n",
        "        if epoch % 3 == 0 and device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    # Test evaluation\n",
        "    print(\"\\nEvaluating on test set...\")\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    test_loss, test_acc, test_tile_dist = validate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Training Complete!\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    print(f\"Best Val Accuracy: {best_val_acc:.2f}%\")\n",
        "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "    print(f\"Test Avg Tile Distance: {test_tile_dist:.2f} tiles\")\n",
        "    print(f\"Total Training Time: {total_time:.1f}s ({total_time/60:.1f} min)\\n\")\n",
        "\n",
        "    # Training history table\n",
        "    headers = ['Epoch', 'Train Loss', 'Train Acc', 'Val Loss', 'Val Acc', 'Tile Dist', 'Time']\n",
        "    print(tabulate(results, headers=headers, tablefmt='simple'))\n",
        "\n",
        "    # Inference speed test\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Inference Speed Test\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    model.eval()\n",
        "    test_input = torch.randn(1, NUM_HEATMAPS, FRAME_HEIGHT, FRAME_WIDTH).to(device)\n",
        "\n",
        "    # Warmup\n",
        "    with torch.no_grad():\n",
        "        for _ in range(10):\n",
        "            _ = model(test_input)\n",
        "\n",
        "    # Measure\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    inference_times = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(100):\n",
        "            start = time.time()\n",
        "            output = model(test_input)\n",
        "            if device == \"cuda\":\n",
        "                torch.cuda.synchronize()\n",
        "            inference_times.append(time.time() - start)\n",
        "\n",
        "    avg_inf_ms = np.mean(inference_times) * 1000\n",
        "    fps = 1000 / avg_inf_ms\n",
        "\n",
        "    print(f\"Average inference: {avg_inf_ms:.2f}ms\")\n",
        "    print(f\"Throughput: {fps:.1f} FPS\")\n",
        "    print(f\"Can process: {fps/FPS:.1f}x realtime\")\n",
        "\n",
        "    pred_tile = output.argmax(1).item()\n",
        "    x, y = tile_index_to_coords(pred_tile)\n",
        "    print(f\"Sample prediction: Tile {pred_tile} at ({x}, {y})\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Model saved as 'best_model.pth'\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Sample video analysis - show all sampled frames\n",
        "    print(f\"{'='*60}\")\n",
        "    print(\"User Viewing Data - Video 0 (3 seconds, every 5th frame)\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Sample# | Frame# | Time(s) | Tile Index | Tile Grid (x,y)\")\n",
        "    print(f\"{'-'*60}\")\n",
        "    for i in range(FRAMES_PER_VIDEO):\n",
        "        tile_idx = tile_indices_1d[0, i]\n",
        "        tx, ty = tile_index_to_coords(tile_idx)\n",
        "        actual_frame = i * FRAME_SAMPLE_RATE\n",
        "        time_sec = actual_frame / FPS\n",
        "        if i % max(1, FRAMES_PER_VIDEO//12) == 0:  # Show ~12 samples\n",
        "            print(f\"{i:7d} | {actual_frame:6d} | {time_sec:6.2f}  | {tile_idx:10d} | ({tx:2d}, {ty:2d})\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Memory cleanup\n",
        "    del model, train_loader, val_loader, test_loader\n",
        "    gc.collect()\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"GPU memory freed: {torch.cuda.memory_allocated()/1e9:.2f} GB in use\")"
      ]
    }
  ]
}