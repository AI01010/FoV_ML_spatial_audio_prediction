{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI01010/FoV_ML_spatial_audio_prediction/blob/main/FoV_ML_spatial_audio_prediction_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDOEiervAH6b"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision joblib pandas tqdm tabulate --quiet\n",
        "\n",
        "import time, os, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import numpy as np, pandas as pd\n",
        "from tabulate import tabulate\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Configuration\n",
        "FRAME_WIDTH = 3840  # 4K width\n",
        "FRAME_HEIGHT = 1920  # 4K height (ERP format)\n",
        "TILES_X = 16\n",
        "TILES_Y = 9\n",
        "NUM_TILES = TILES_X * TILES_Y  # 144 tiles\n",
        "TILE_WIDTH = FRAME_WIDTH // TILES_X  # 240px\n",
        "TILE_HEIGHT = FRAME_HEIGHT // TILES_Y  # ~213px\n",
        "NUM_HEATMAPS = 5  # 3 audio + 2 video\n",
        "\n",
        "class SaliencyTileDataset(Dataset):\n",
        "    \"\"\"Dataset for saliency heatmaps and corresponding tile indices\"\"\"\n",
        "    \n",
        "    def __init__(self, heatmaps, tile_indices, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            heatmaps: numpy array of shape (N, NUM_HEATMAPS, H, W)\n",
        "            tile_indices: numpy array of shape (N,) with tile indices [0-143]\n",
        "            transform: optional transform to apply\n",
        "        \"\"\"\n",
        "        self.heatmaps = torch.FloatTensor(heatmaps)\n",
        "        self.tile_indices = torch.LongTensor(tile_indices)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.tile_indices)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        heatmap = self.heatmaps[idx]\n",
        "        tile_idx = self.tile_indices[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            heatmap = self.transform(heatmap)\n",
        "            \n",
        "        return heatmap, tile_idx\n",
        "\n",
        "\n",
        "class HeatmapFusionCNN(nn.Module):\n",
        "    \"\"\"CNN for fusing multiple saliency heatmaps and predicting tile indices\"\"\"\n",
        "    \n",
        "    def __init__(self, num_heatmaps=5, num_tiles=144, dropout=0.3):\n",
        "        super(HeatmapFusionCNN, self).__init__()\n",
        "        \n",
        "        # Initial fusion layer to weight heatmaps\n",
        "        self.heatmap_weights = nn.Conv2d(num_heatmaps, 16, kernel_size=1, padding=0)\n",
        "        \n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(16, 32, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        # Adaptive pooling to handle variable input sizes\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 3))\n",
        "        \n",
        "        # Fully connected layers for classification\n",
        "        self.fc1 = nn.Linear(256 * 6 * 3, 512)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.fc3 = nn.Linear(256, num_tiles)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Fuse heatmaps with learnable weights\n",
        "        x = self.heatmap_weights(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        # Feature extraction\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool3(x)\n",
        "        \n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        # Adaptive pooling\n",
        "        x = self.adaptive_pool(x)\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Classification\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        \n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "def tile_coords_to_index(x, y, tiles_x=TILES_X):\n",
        "    \"\"\"Convert tile coordinates to linear index\"\"\"\n",
        "    return y * tiles_x + x\n",
        "\n",
        "\n",
        "def tile_index_to_coords(idx, tiles_x=TILES_X):\n",
        "    \"\"\"Convert linear index to tile coordinates\"\"\"\n",
        "    y = idx // tiles_x\n",
        "    x = idx % tiles_x\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def tile_distance(pred_idx, true_idx, tiles_x=TILES_X, tiles_y=TILES_Y):\n",
        "    \"\"\"Calculate Euclidean distance between predicted and true tile\"\"\"\n",
        "    px, py = tile_index_to_coords(pred_idx, tiles_x)\n",
        "    tx, ty = tile_index_to_coords(true_idx, tiles_x)\n",
        "    return np.sqrt((px - tx)**2 + (py - ty)**2)\n",
        "\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for heatmaps, tile_indices in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        heatmaps = heatmaps.to(device)\n",
        "        tile_indices = tile_indices.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(heatmaps)\n",
        "        loss = criterion(outputs, tile_indices)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += tile_indices.size(0)\n",
        "        correct += predicted.eq(tile_indices).sum().item()\n",
        "    \n",
        "    return total_loss / len(dataloader), 100. * correct / total\n",
        "\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    tile_distances = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for heatmaps, tile_indices in tqdm(dataloader, desc=\"Validating\", leave=False):\n",
        "            heatmaps = heatmaps.to(device)\n",
        "            tile_indices = tile_indices.to(device)\n",
        "            \n",
        "            outputs = model(heatmaps)\n",
        "            loss = criterion(outputs, tile_indices)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += tile_indices.size(0)\n",
        "            correct += predicted.eq(tile_indices).sum().item()\n",
        "            \n",
        "            # Calculate tile distances\n",
        "            for pred, true in zip(predicted.cpu().numpy(), tile_indices.cpu().numpy()):\n",
        "                tile_distances.append(tile_distance(pred, true))\n",
        "    \n",
        "    avg_distance = np.mean(tile_distances)\n",
        "    return total_loss / len(dataloader), 100. * correct / total, avg_distance\n",
        "\n",
        "\n",
        "def generate_synthetic_data(num_samples=1000):\n",
        "    \"\"\"Generate synthetic heatmap data for demonstration\"\"\"\n",
        "    print(\"Generating synthetic data...\")\n",
        "    \n",
        "    heatmaps = []\n",
        "    tile_indices = []\n",
        "    \n",
        "    for _ in range(num_samples):\n",
        "        # Generate 5 heatmaps with different patterns\n",
        "        sample_heatmaps = []\n",
        "        \n",
        "        # Create random focal points for each heatmap\n",
        "        for h in range(NUM_HEATMAPS):\n",
        "            heatmap = np.zeros((FRAME_HEIGHT, FRAME_WIDTH))\n",
        "            \n",
        "            # Random focal point\n",
        "            cx = np.random.randint(0, FRAME_WIDTH)\n",
        "            cy = np.random.randint(0, FRAME_HEIGHT)\n",
        "            \n",
        "            # Create Gaussian-like saliency\n",
        "            y, x = np.ogrid[:FRAME_HEIGHT, :FRAME_WIDTH]\n",
        "            distance = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
        "            heatmap = np.exp(-distance**2 / (2 * (FRAME_WIDTH/6)**2))\n",
        "            \n",
        "            sample_heatmaps.append(heatmap)\n",
        "        \n",
        "        # Stack heatmaps\n",
        "        stacked = np.stack(sample_heatmaps, axis=0)\n",
        "        heatmaps.append(stacked)\n",
        "        \n",
        "        # Find most salient tile (where max value is)\n",
        "        fused = np.mean(sample_heatmaps, axis=0)\n",
        "        max_y, max_x = np.unravel_index(fused.argmax(), fused.shape)\n",
        "        tile_x = min(max_x // TILE_WIDTH, TILES_X - 1)\n",
        "        tile_y = min(max_y // TILE_HEIGHT, TILES_Y - 1)\n",
        "        tile_idx = tile_coords_to_index(tile_x, tile_y)\n",
        "        \n",
        "        tile_indices.append(tile_idx)\n",
        "    \n",
        "    return np.array(heatmaps), np.array(tile_indices)\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"360Â° Video Saliency-Based Tile Predictor\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    print(f\"Configuration:\")\n",
        "    print(f\"  Frame size: {FRAME_WIDTH}x{FRAME_HEIGHT}\")\n",
        "    print(f\"  Grid: {TILES_X}x{TILES_Y} = {NUM_TILES} tiles\")\n",
        "    print(f\"  Tile size: {TILE_WIDTH}x{TILE_HEIGHT}\")\n",
        "    print(f\"  Number of heatmaps: {NUM_HEATMAPS}\")\n",
        "    print(f\"  Device: {device}\\n\")\n",
        "    \n",
        "    # Generate synthetic data\n",
        "    heatmaps, tile_indices = generate_synthetic_data(num_samples=2000)\n",
        "    \n",
        "    # Create dataset\n",
        "    dataset = SaliencyTileDataset(heatmaps, tile_indices)\n",
        "    \n",
        "    # Split into train/val/test\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    \n",
        "    train_dataset, val_dataset, test_dataset = random_split(\n",
        "        dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "    \n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "    \n",
        "    print(f\"Dataset splits:\")\n",
        "    print(f\"  Training: {len(train_dataset)} samples\")\n",
        "    print(f\"  Validation: {len(val_dataset)} samples\")\n",
        "    print(f\"  Test: {len(test_dataset)} samples\\n\")\n",
        "    \n",
        "    # Initialize model\n",
        "    model = HeatmapFusionCNN(num_heatmaps=NUM_HEATMAPS, num_tiles=NUM_TILES).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
        "    \n",
        "    # Training\n",
        "    num_epochs = 20\n",
        "    best_val_acc = 0\n",
        "    results = []\n",
        "    \n",
        "    print(\"Starting training...\\n\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start = time.time()\n",
        "        \n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc, avg_tile_dist = validate(model, val_loader, criterion, device)\n",
        "        \n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        epoch_time = time.time() - epoch_start\n",
        "        \n",
        "        results.append({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Train Loss': f\"{train_loss:.4f}\",\n",
        "            'Train Acc': f\"{train_acc:.2f}%\",\n",
        "            'Val Loss': f\"{val_loss:.4f}\",\n",
        "            'Val Acc': f\"{val_acc:.2f}%\",\n",
        "            'Avg Tile Dist': f\"{avg_tile_dist:.2f}\",\n",
        "            'Time': f\"{epoch_time:.2f}s\"\n",
        "        })\n",
        "        \n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
        "            print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "            print(f\"  Avg Tile Distance: {avg_tile_dist:.2f} tiles\")\n",
        "            print(f\"  Time: {epoch_time:.2f}s\\n\")\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    \n",
        "    # Final evaluation on test set\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    test_loss, test_acc, test_tile_dist = validate(model, test_loader, criterion, device)\n",
        "    \n",
        "    # Results summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Training Complete!\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    print(\"Final Results:\")\n",
        "    print(f\"  Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "    print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
        "    print(f\"  Test Avg Tile Distance: {test_tile_dist:.2f} tiles\")\n",
        "    print(f\"  Total Training Time: {total_time/60:.2f} minutes\")\n",
        "    print(f\"  Avg Time per Epoch: {total_time/num_epochs:.2f}s\\n\")\n",
        "    \n",
        "    # Display results table\n",
        "    print(\"\\nTraining History:\")\n",
        "    print(tabulate(results, headers='keys', tablefmt='grid'))\n",
        "    \n",
        "    # Inference speed test\n",
        "    print(\"\\nInference Speed Test:\")\n",
        "    model.eval()\n",
        "    test_input = torch.randn(1, NUM_HEATMAPS, FRAME_HEIGHT, FRAME_WIDTH).to(device)\n",
        "    \n",
        "    # Warmup\n",
        "    with torch.no_grad():\n",
        "        for _ in range(10):\n",
        "            _ = model(test_input)\n",
        "    \n",
        "    # Measure\n",
        "    torch.cuda.synchronize() if device == \"cuda\" else None\n",
        "    inference_times = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(100):\n",
        "            start = time.time()\n",
        "            output = model(test_input)\n",
        "            torch.cuda.synchronize() if device == \"cuda\" else None\n",
        "            inference_times.append(time.time() - start)\n",
        "    \n",
        "    avg_inference = np.mean(inference_times) * 1000  # Convert to ms\n",
        "    fps = 1000 / avg_inference\n",
        "    \n",
        "    # take 3-5 heatmaps of a single frame\n",
        "    # tile each into 16*9 tiles and label each tile with single index going per column from left to right, per row from top to bottom\n",
        "    # convert into 3d matrix (each depth is a heatmap)  \n",
        "    # size of input matrix (16*pixWidthPerTile)*(9*pixHeightPerTile)*(3|4|5)\n",
        "    # assume 4k consumer/customer market standard: 4k(3840x1920)\n",
        "    # also take the head direction center and the corresponding tile's index for data per frame as input\n",
        "    # we should be taking the 3d matrix of heatmaps and the tile index where the user is looking per frame as out data\n",
        "    # predict the tile that the user will look at based on the heatmaps (weighted by each heatmap then fused) to find the tile with highest saliency\n",
        "    # check the predicted tile index vs the actual inputted tile index for user view\n",
        "    # loss/error function will be the difference in tile index (using the standard loss func) to optimize by minimizing the loss\n",
        "    # do this per frame and get an accuracy as well as runtime calculation\n",
        "\n",
        "    print(f\"  Average inference time: {avg_inference:.2f}ms\")\n",
        "    print(f\"  Throughput: {fps:.1f} FPS\")\n",
        "    print(f\"  Predicted tile index: {output.argmax(1).item()}\")\n",
        "    \n",
        "    x, y = tile_index_to_coords(output.argmax(1).item())\n",
        "    print(f\"  Predicted tile coordinates: ({x}, {y})\\n\")\n",
        "    \n",
        "    print(\"Model saved as 'best_model.pth'\")\n",
        "    print(f\"{'='*60}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN+BM/UWFMAZWotp6LJ+axG",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
