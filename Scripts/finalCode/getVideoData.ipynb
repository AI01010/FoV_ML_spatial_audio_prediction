{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3f0b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1212452014.py, line 33)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31merp_height=1920, erp_width=3840, sample_every_n_frames=5, numHeatmaps=7):\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from Scripts.finalCode.getAudioSaliency import compute_audio_saliency_heatmap_vectorized, precompute_integrals\n",
    "from Scripts.finalCode.getVideoLabels import filterDf, uv_to_tile_index\n",
    "from Scripts.finalCode.getVideoSaliency import compute_video_saliency_heatmap_vectorized\n",
    "\n",
    "def normalize_heatmaps(heatmaps):\n",
    "    \"\"\"Normalize heatmap to [0, 1] range.\"\"\"\n",
    "    # returns a list of mins and maxs for each heatmap\n",
    "    h_mins = np.min(heatmaps, axis=(1, 2), keepdims=True)\n",
    "    h_maxs = np.max(heatmaps, axis=(1, 2), keepdims=True)\n",
    "\n",
    "    return (heatmaps - h_mins) / (h_maxs - h_mins)\n",
    "\n",
    "\n",
    "def getFrame(cap, output_width, output_height, frame_idx):    \n",
    "    \"\"\"\n",
    "    Read video and yield resized frames.\n",
    "    \"\"\"\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "    ret, frame = cap.read()        \n",
    "    resized_frame = cv2.resize(frame, (output_width, output_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return resized_frame\n",
    "\n",
    "def process_360_video(video_name, video_path, audio_path, outputX_path, outputY_path,\n",
    "                      csv_path, erp_height=1920, erp_width=3840, \n",
    "                      sample_every_n_frames=5, numHeatmaps=7, participant_id = 1,\n",
    "                      cols = 16, rows = 9):\n",
    "    \"\"\"\n",
    "    Main pipeline to process a 360 video and extract audio saliency heatmaps.\n",
    "    \n",
    "    Parameters:\n",
    "        video_path: path to ERP format 360 video\n",
    "        audio_path: path to first-order ambisonic audio file\n",
    "        output_path: where to save the output .npy file\n",
    "        erp_height: height of ERP format (pixels)\n",
    "        erp_width: width of ERP format (pixels)\n",
    "        sample_every_n_frames: sample every N frames\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load audio\n",
    "    print(\"Loading ambisonic audio...\")\n",
    "    audio_data, audio_samplerate = sf.read(audio_path)\n",
    "    \n",
    "    # Check for 4 channels\n",
    "    if len(audio_data.shape) == 1:\n",
    "        raise ValueError(f\"Audio is mono. Expected 4-channel first-order ambisonics.\")\n",
    "    elif audio_data.shape[1] != 4:\n",
    "        raise ValueError(f\"Audio has {audio_data.shape[1]} channels. Expected 4-channel first-order ambisonics (W, X, Y, Z).\")\n",
    "    \n",
    "    # Split into channels\n",
    "    W = audio_data[:, 0]\n",
    "    X = audio_data[:, 1]\n",
    "    Y = audio_data[:, 2]\n",
    "    Z = audio_data[:, 3]\n",
    "    \n",
    "    print(f\"Audio shape: {audio_data.shape}\")\n",
    "    print(f\"Audio sample rate: {audio_samplerate} Hz\")\n",
    "    print(\"Successfully loaded 4-channel first-order ambisonics audio\")\n",
    "    \n",
    "    # Open video to get metadata\n",
    "    print(\"Opening video...\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video: {video_path}\")\n",
    "    \n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(f\"Video FPS: {video_fps}\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(f\"Video dimensions: {video_width}x{video_height}\")\n",
    "    \n",
    "    # Check if resizing is needed\n",
    "    need_resize = video_width != erp_width or video_height != erp_height\n",
    "    if need_resize:\n",
    "        print(f\"Video will be resized from {video_width}x{video_height} to {erp_width}x{erp_height}\")\n",
    "    \n",
    "    # Precompute integrals for coarse tiles (20x20 degrees)\n",
    "    tile_cache = precompute_integrals(tile_size_deg=20)\n",
    "    \n",
    "    # Calculate number of sampled frames\n",
    "    num_sampled_frames = (total_frames - math.ceil(sample_every_n_frames / 2)) // sample_every_n_frames\n",
    "\n",
    "    labelDf = filterDf(csv_path, participant_id, video_name)\n",
    "    tile_indices = []\n",
    "    \n",
    "    # Initialize output array\n",
    "    output_array = np.zeros((num_sampled_frames, numHeatmaps, erp_height, erp_width), dtype=np.float16)\n",
    "    \n",
    "    print(f\"Output array shape: {output_array.shape}\")\n",
    "    print(f\"Processing {num_sampled_frames} frames...\")\n",
    "        \n",
    "    # Use frame generator (resizes all frames upfront in the stream). Also, only retrieves them one at a time, instead of keeping it all in memory\n",
    "    for sampled_frame_idx in range(num_sampled_frames):\n",
    "        frame_idx = sample_every_n_frames * (sampled_frame_idx + 1)\n",
    "\n",
    "        prevFrame = getFrame(cap, erp_height, erp_width, frame_idx - 1)\n",
    "        frame = getFrame(cap, erp_height, erp_width, frame_idx)\n",
    "        \n",
    "        print(f\"Processing frame {frame_idx}/{total_frames} (sample {sampled_frame_idx}/{num_sampled_frames})\")\n",
    "        \n",
    "        # Compute audio saliency heatmap\n",
    "        saliency_heatmaps = np.concat(compute_audio_saliency_heatmap_vectorized(W, X, Y, Z, audio_samplerate,\n",
    "                                                                        frame_idx, video_fps,\n",
    "                                                                        erp_height, erp_width,\n",
    "                                                                        tile_cache, sample_every_n_frames,\n",
    "                                                                        numHeatmaps-2, tile_size_deg=20),\n",
    "                                      compute_video_saliency_heatmap_vectorized(prevFrame, frame, frame_idx, video_fps,\n",
    "                                                                        erp_height, erp_width,\n",
    "                                                                        tile_cache, sample_every_n_frames,\n",
    "                                                                        numHeatmaps-7, tile_size_deg=20)\n",
    "                                      )\n",
    "        \n",
    "        # Normalize heatmap\n",
    "        saliency_heatmaps = normalize_heatmaps(saliency_heatmaps)\n",
    "        \n",
    "        # Store in output array\n",
    "        output_array[sampled_frame_idx] = saliency_heatmaps\n",
    "\n",
    "                # Find the row with closest timestamp\n",
    "        idx = (labelDf['t'] - labelDf).abs().idxmin()\n",
    "\n",
    "        # Get u, v coordinates\n",
    "        u = labelDf.loc[idx, 'u']\n",
    "        v = labelDf.loc[idx, 'v']\n",
    "\n",
    "        # Convert to tile index\n",
    "        tile_idx = uv_to_tile_index(u, v, rows, cols)\n",
    "        tile_indices.append(tile_idx)\n",
    "    \n",
    "    tile_indices_array = np.array(tile_indices)\n",
    "\n",
    "    print(f\"\\nGenerated {len(tile_indices_array)} tile indices\")\n",
    "    print(f\"Tile index range: {tile_indices_array.min()} to {tile_indices_array.max()}\")\n",
    "\n",
    "    print(f\"Saving output to {outputX_path}...\")\n",
    "    np.save(outputY_path, tile_indices_array)\n",
    "    print(f\"Done! Output shape: {output_array.shape}\")\n",
    "    print(f\"Saved to: {outputY_path}\")\n",
    "\n",
    "    \n",
    "    # Save output\n",
    "    print(f\"Saving output to {outputX_path}...\")\n",
    "    np.save(outputX_path, output_array)\n",
    "    print(f\"Done! Output shape: {output_array.shape}\")\n",
    "    print(f\"Saved to: {outputX_path}\")\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    os.chdir(\"./../..\")\n",
    "    \n",
    "    # Configuration - modify as needed\n",
    "    ERP_WIDTH = 1920  # width\n",
    "    ERP_HEIGHT = 960  # height\n",
    "    SAMPLE_RATE = 5  # sample every 5 frames\n",
    "    FILE_NAME = \"5020\"\n",
    "    VIDEO_PATH = f\"Data/Pre-Processed-Data/{FILE_NAME}.mp4\"  # ERP format 360 video\n",
    "    AUDIO_PATH = f\"Data/Pre-Processed-Data/{FILE_NAME}.wav\"\n",
    "    INPUT_CSV_PATH = f\"Data/Pre-Processed-Data/{FILE_NAME}.csv\"\n",
    "    OUTPUT_X_PATH = f\"FinalTrainingData/{FILE_NAME}_heatmaps.npy\"\n",
    "    OUTPUT_Y_PATH = f\"FinalTrainingData/{FILE_NAME}_labels.npy\"\n",
    "    NUM_HEATMAPS = 7\n",
    "    PARTICIPANT_ID = 1\n",
    "    TILE_COLS = 16\n",
    "    TILE_ROWS = 9\n",
    "\n",
    "    \n",
    "    # Run the pipeline\n",
    "    process_360_video(FILE_NAME, VIDEO_PATH, AUDIO_PATH, OUTPUT_X_PATH, OUTPUT_Y_PATH, INPUT_CSV_PATH,\n",
    "                                      erp_height=ERP_HEIGHT, erp_width=ERP_WIDTH,\n",
    "                                      sample_every_n_frames=SAMPLE_RATE, numHeatmaps=NUM_HEATMAPS,\n",
    "                                      participant_id = PARTICIPANT_ID, cols=TILE_COLS, rows=TILE_ROWS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
