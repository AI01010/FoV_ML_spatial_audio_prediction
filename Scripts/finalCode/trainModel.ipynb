{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d09c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from Scripts.finalCode.model import HeatmapFusionCNN, SaliencyTileDataset\n",
    "\n",
    "# Generate synthetic video data - just 1 video for memory efficiency\n",
    "num_videos = 1  # 1 video of 3 seconds\n",
    "heatmaps_4d, tile_indices_1d = generate_synthetic_video_data(num_videos=num_videos)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"Data Structure:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"4D Heatmaps Matrix: {heatmaps_4d.shape}\")\n",
    "print(f\"  [videos, sampled_frames, heatmaps, height, width]\")\n",
    "print(f\"  [1, 36, 9, 480, 960]\")\n",
    "print(f\"  - 1 video\")\n",
    "print(f\"  - 36 sampled frames (every 5th frame from 180 total @ 60 FPS)\")\n",
    "print(f\"  - 9 heatmaps per frame (7 audio + 2 video)\")\n",
    "print(f\"  - 480x960 resolution (25% of 4K)\")\n",
    "print(f\"\\n1D Tile Index Array: {tile_indices_1d.shape}\")\n",
    "print(f\"  [videos, sampled_frames]\")\n",
    "print(f\"  [1, 36]\")\n",
    "print(f\"  - 1 user's viewing data\")\n",
    "print(f\"  - 36 tile indices (sampled every 5th frame, range 0-143)\")\n",
    "print(f\"  - Each index represents which tile user is looking at\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Flatten data for training\n",
    "heatmaps_flat, tile_indices_flat = flatten_video_data(heatmaps_4d, tile_indices_1d)\n",
    "\n",
    "print(f\"Flattened for Training:\")\n",
    "print(f\"  Heatmaps: {heatmaps_flat.shape}\")\n",
    "print(f\"  Tile indices: {tile_indices_flat.shape}\\n\")\n",
    "\n",
    "# Create dataset\n",
    "dataset = SaliencyTileDataset(heatmaps_flat, tile_indices_flat)\n",
    "\n",
    "# Split\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Dataset splits:\")\n",
    "print(f\"  Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\\n\")\n",
    "\n",
    "# Initialize model\n",
    "model = HeatmapFusionCNN(num_heatmaps=NUM_HEATMAPS, num_tiles=NUM_TILES).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params:,}\\n\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Training\n",
    "num_epochs = 15\n",
    "best_val_acc = 0\n",
    "results = []\n",
    "\n",
    "print(\"Training started...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, avg_tile_dist = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    epoch_time = time.time() - epoch_start\n",
    "\n",
    "    results.append([\n",
    "        epoch + 1,\n",
    "        f\"{train_loss:.4f}\",\n",
    "        f\"{train_acc:.1f}%\",\n",
    "        f\"{val_loss:.4f}\",\n",
    "        f\"{val_acc:.1f}%\",\n",
    "        f\"{avg_tile_dist:.2f}\",\n",
    "        f\"{epoch_time:.1f}s\"\n",
    "    ])\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "            f\"Train {train_acc:.1f}% | Val {val_acc:.1f}% | \"\n",
    "            f\"Dist {avg_tile_dist:.2f} | {epoch_time:.1f}s\")\n",
    "\n",
    "    # Clear cache periodically\n",
    "    if epoch % 3 == 0 and device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "# Test evaluation\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "test_loss, test_acc, test_tile_dist = validate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Training Complete!\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(f\"Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"Test Avg Tile Distance: {test_tile_dist:.2f} tiles\")\n",
    "print(f\"Total Training Time: {total_time:.1f}s ({total_time/60:.1f} min)\\n\")\n",
    "\n",
    "# Training history table\n",
    "headers = ['Epoch', 'Train Loss', 'Train Acc', 'Val Loss', 'Val Acc', 'Tile Dist', 'Time']\n",
    "print(tabulate(results, headers=headers, tablefmt='simple'))\n",
    "\n",
    "# Inference speed test\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Inference Speed Test\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "model.eval()\n",
    "test_input = torch.randn(1, NUM_HEATMAPS, FRAME_HEIGHT, FRAME_WIDTH).to(device)\n",
    "\n",
    "# Warmup\n",
    "with torch.no_grad():\n",
    "    for _ in range(10):\n",
    "        _ = model(test_input)\n",
    "\n",
    "# Measure\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "inference_times = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(100):\n",
    "        start = time.time()\n",
    "        output = model(test_input)\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        inference_times.append(time.time() - start)\n",
    "\n",
    "avg_inf_ms = np.mean(inference_times) * 1000\n",
    "fps = 1000 / avg_inf_ms\n",
    "\n",
    "print(f\"Average inference: {avg_inf_ms:.2f}ms\")\n",
    "print(f\"Throughput: {fps:.1f} FPS\")\n",
    "print(f\"Can process: {fps/FPS:.1f}x realtime\")\n",
    "\n",
    "pred_tile = output.argmax(1).item()\n",
    "x, y = tile_index_to_coords(pred_tile)\n",
    "print(f\"Sample prediction: Tile {pred_tile} at ({x}, {y})\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Model saved as 'best_model.pth'\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Sample video analysis - show all sampled frames\n",
    "print(f\"{'='*60}\")\n",
    "print(\"User Viewing Data - Video 0 (3 seconds, every 5th frame)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Sample# | Frame# | Time(s) | Tile Index | Tile Grid (x,y)\")\n",
    "print(f\"{'-'*60}\")\n",
    "for i in range(FRAMES_PER_VIDEO):\n",
    "    tile_idx = tile_indices_1d[0, i]\n",
    "    tx, ty = tile_index_to_coords(tile_idx)\n",
    "    actual_frame = i * FRAME_SAMPLE_RATE\n",
    "    time_sec = actual_frame / FPS\n",
    "    if i % max(1, FRAMES_PER_VIDEO//12) == 0:  # Show ~12 samples\n",
    "        print(f\"{i:7d} | {actual_frame:6d} | {time_sec:6.2f}  | {tile_idx:10d} | ({tx:2d}, {ty:2d})\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Memory cleanup\n",
    "del model, train_loader, val_loader, test_loader\n",
    "gc.collect()\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU memory freed: {torch.cuda.memory_allocated()/1e9:.2f} GB in use\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
